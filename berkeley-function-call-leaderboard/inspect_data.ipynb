{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "from pprint import pp\n",
    "\n",
    "import pandas as pd\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories(path):\n",
    "    dirs = [dir for dir in os.listdir(path) if os.path.isdir(os.path.join(path, dir))]\n",
    "    return dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    lines = []\n",
    "    with open(path, \"r\") as file:\n",
    "        for line in file:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_dir(model_dirs, gen_mode, model_name_escaped, dedup_str, n_tool_calls):\n",
    "    for model_dir in model_dirs:\n",
    "        if gen_mode == \"structured\" and \"unstructured\" in model_dir:\n",
    "            continue\n",
    "\n",
    "        if gen_mode in model_dir and model_name_escaped in model_dir and dedup_str in model_dir and n_tool_calls in model_dir:\n",
    "            return model_dir\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_it(idx, questions, solutions, generations, scores, idx_type=\"error\"):\n",
    "\n",
    "    if idx_type == \"absolute\":\n",
    "        question = questions[idx]\n",
    "        solution = solutions[idx]\n",
    "        generation = generations[idx]\n",
    "        score = [score for i, score in enumerate(scores) if i > 0 and score[\"id\"] == idx]\n",
    "    elif idx_type == \"error\":\n",
    "        if idx+1 > len(scores):\n",
    "            raise ValueError(f\"There are {len(scores)-1} errors in this file. But you requested error {idx} (0-index).\")\n",
    "        score = scores[idx+1]\n",
    "        abs_idx = score[\"id\"] - 1\n",
    "        question = questions[abs_idx]\n",
    "        solution = solutions[abs_idx]\n",
    "        generation = generations[abs_idx]\n",
    "    else:\n",
    "        raise ValueError(\"Wrong idx_type.\")\n",
    "\n",
    "    return question, solution, generation, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values( question, solution, generation, score):\n",
    "    user_query = question[\"question\"]\n",
    "    tools = question[\"function\"]\n",
    "    if not isinstance(tools, list):\n",
    "        tools = [tools]\n",
    "\n",
    "    raw_result = generation[\"result\"]\n",
    "    messages = generation[\"messages\"]\n",
    "    tool_calls = generation[\"tool_calls\"]\n",
    "    n_tool_calls = generation[\"n_tool_calls\"]\n",
    "    valid = score[\"valid\"]\n",
    "    error = score[\"error\"]\n",
    "    error_type = score[\"error_type\"]\n",
    "    decoded_result = score[\"model_result_decoded\"] if \"model_result_decoded\" in score else None\n",
    "\n",
    "    result = {\n",
    "        \"user_query\": user_query,\n",
    "        \"tools\": tools,\n",
    "        \"valid\": valid,\n",
    "        \"tool_calls\": tool_calls,\n",
    "        \"solution\": solution,\n",
    "        \"error\": error,\n",
    "        \"error_type\": error_type,\n",
    "        \"raw_result\": raw_result,\n",
    "        \"decoded_result\": decoded_result,\n",
    "        \"messages\": messages,\n",
    "        \"n_tool_calls\": n_tool_calls\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_to_result(spec, idx, idx_type):\n",
    "\n",
    "    # Unpack spec\n",
    "    bfcl_category = spec[\"bfcl_category\"]\n",
    "    model_name = spec[\"model_name\"]\n",
    "    dedup = spec[\"dedup\"]\n",
    "    out_dir = spec[\"out_dir\"]\n",
    "    gen_mode = spec[\"gen_mode\"]\n",
    "    n_tool_calls = spec[\"n_tool_calls\"]\n",
    "\n",
    "    # Get paths\n",
    "    test_file = f\"gorilla_openfunctions_v1_test_{bfcl_category}.json\"\n",
    "    questions_path = os.path.join(\"./data\", test_file)\n",
    "    solutions_path = os.path.join(\"./data/possible_answer\", test_file)\n",
    "\n",
    "    model_name_escaped = model_name.replace(\"/\", \"_\")\n",
    "    dedup_str = \"dedup\" if dedup else \"\"\n",
    "    model_dirs = get_directories(out_dir)\n",
    "    model_dir = get_model_dir(model_dirs, gen_mode, model_name_escaped, dedup_str, n_tool_calls)\n",
    "    generations_path = os.path.join(out_dir, model_dir, \"generations\", test_file)\n",
    "    scores_path = os.path.join(out_dir, model_dir, \"scores\", bfcl_category + \"_score.json\")\n",
    "\n",
    "    # Load all files\n",
    "    questions = load_jsonl(questions_path)\n",
    "    solutions = load_jsonl(solutions_path)\n",
    "    generations = load_jsonl(generations_path)\n",
    "    scores = load_jsonl(scores_path)\n",
    "\n",
    "    # Index into the exact question, solution, generation, score\n",
    "    question, solution, generation, score = index_it(idx, questions, solutions, generations, scores, idx_type=idx_type)\n",
    "    values = extract_values(question, solution, generation, score)\n",
    "\n",
    "    result = spec | values | {\"idx\": idx, \"idx_type\": idx_type}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_result(result, width=200, verbose=0):\n",
    "    print(\"-\"*120)\n",
    "    dedup_str = \"-dedup\" if dedup else \"\"\n",
    "    print(f\"Example {result['idx']} of {result['bfcl_category']} BFCL\\t\\t\\t\\t({result['model_name']}\\t{result['gen_mode']}\\t{result['n_tool_calls']}{dedup_str})\")\n",
    "    print(\"-\"*120, end=\"\\n\\n\")\n",
    "\n",
    "    color_map = {}\n",
    "    print(colored(f\"User Query:\\n{result['user_query']}\", \"yellow\"), end=\"\\n\\n\")\n",
    "\n",
    "    print(colored(f\"Valid: {result['valid']}\", \"blue\"), end=\"\\n\\n\")\n",
    "\n",
    "    print(colored(f\"Error:\\n{result['error']}\\n{result['error_type']}\", \"blue\"), end=\"\\n\\n\")\n",
    "\n",
    "    print(colored(\"My Tool Calls:\", \"red\"))\n",
    "    for tool_call in result['tool_calls']:\n",
    "        print(colored(tool_call, \"red\"))\n",
    "    print()\n",
    "\n",
    "    print(colored(\"Correct Tool Calls:\", \"green\"))\n",
    "    for tool_name, tool_args in result['solution'].items():\n",
    "        print(colored(f\"{{'tool_name': '{tool_name}', 'tool_arguments': {tool_args}}}\", \"green\"))\n",
    "    print()\n",
    "\n",
    "    print(colored(f\"Raw Result:\\n{result['raw_result']}\", \"yellow\"), end=\"\\n\\n\")\n",
    "\n",
    "    if verbose >= 1:\n",
    "\n",
    "        print(colored(f\"Decoded Result:\\n{result['decoded_result']}\", \"blue\"), end=\"\\n\\n\")\n",
    "\n",
    "        print(\"Given Tool Calls:\")\n",
    "        for tool in result[\"tools\"]:\n",
    "            pp(tool, width=width)\n",
    "        print()\n",
    "\n",
    "    if verbose >= 2:\n",
    "        print(\"Messages:\")\n",
    "        pretty_print_conversation(result['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "bfcl_category = \"multiple_function\"\n",
    "\n",
    "dedup = False\n",
    "gen_mode = \"meta_tool\"\n",
    "n_tool_calls = \"auto\"\n",
    "model_name = \"databricks/dbrx-instruct\"\n",
    "out_dir = \"./outputs\"\n",
    "\n",
    "spec = {\n",
    "    \"bfcl_category\": bfcl_category,\n",
    "    \"gen_mode\": gen_mode,\n",
    "    \"n_tool_calls\": n_tool_calls,\n",
    "    \"model_name\": model_name,\n",
    "    \"dedup\": dedup,\n",
    "    \"out_dir\": out_dir,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Example 2 of multiple_function BFCL\t\t\t\t(databricks/dbrx-instruct\tmeta_tool\tauto)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[33mUser Query:\n",
      "How to assess the population growth in deer and their impact on woodland in Washington state over the past decade?\u001b[0m\n",
      "\n",
      "\u001b[34mValid: False\u001b[0m\n",
      "\n",
      "\u001b[34mError:\n",
      "['Wrong number of functions.']\n",
      "parallel_function_checker_no_order:wrong_count\u001b[0m\n",
      "\n",
      "\u001b[31mMy Tool Calls:\u001b[0m\n",
      "\u001b[31m{'tool_name': 'wildlife_population.assess_growth', 'tool_arguments': {'species': 'deer', 'location': 'Washington state', 'duration': 10}}\u001b[0m\n",
      "\u001b[31m{'tool_name': 'ecological_impact.analyze', 'tool_arguments': {'species': 'deer', 'ecosystem': 'woodland', 'location': 'Washington state', 'timeframe': 10}}\u001b[0m\n",
      "\u001b[31m{'tool_name': 'wildlife_population.assess_growth', 'tool_arguments': {'species': 'deer', 'location': 'Washington state', 'duration': 10}}\u001b[0m\n",
      "\n",
      "\u001b[32mCorrect Tool Calls:\u001b[0m\n",
      "\u001b[32m{'tool_name': 'wildlife_population.assess_growth', 'tool_arguments': {'species': ['deer', 'Deer'], 'location': ['Washington state', 'WA', 'Washington'], 'duration': [10]}}\u001b[0m\n",
      "\n",
      "\u001b[33mRaw Result:\n",
      "[wildlife_population.assess_growth(species='deer', location='Washington state', duration=10), ecological_impact.analyze(species='deer', ecosystem='woodland', location='Washington state', timeframe=10), wildlife_population.assess_growth(species='deer', location='Washington state', duration=10)]\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "result = spec_to_result(spec, idx, idx_type=\"error\")\n",
    "tools = result[\"tools\"]\n",
    "user_query = result[\"user_query\"]\n",
    "pp_result(result, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Prompt Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tool_use.tool import Tool\n",
    "# from tool_use.prompt import get_meta_tool_system_prompt\n",
    "# from tool_use.utils.meta_tool import get_meta_tool\n",
    "from tool_use.utils.regex_util import tools_to_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tool\n",
    "base_url = \"http://localhost:8000/v1\"\n",
    "api_key = \"-\"\n",
    "model_name = \"databricks/dbrx-instruct\"\n",
    "my_tool = Tool(base_url, api_key, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'pick_relevant_tool',\n",
       " 'description': 'Pick\\'s the relevant tool that corresponds to user\\'s query.Choose the \"none\" keyword if none of the tools are relevant to the user\\'s query. If you have already called a tool, choose the `none` argument. Do not repeat a tool call!',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'name': {'type': 'string',\n",
       "    'description': 'The names of the relevant tools to use',\n",
       "    'enum': ['wildlife_population.assess_growth',\n",
       "     'ecological_impact.analyze',\n",
       "     'none']}},\n",
       "  'required': ['name']}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_meta_tool\n",
    "description = 'Pick\\'s the relevant tool that corresponds to user\\'s query.'\n",
    "description += 'Choose the \"none\" keyword if none of the tools are relevant to the user\\'s query. If you have already called a tool, choose the `none` argument. Do not repeat a tool call!'\n",
    "\n",
    "meta_tool = {\n",
    "    'name': 'pick_relevant_tool',\n",
    "    'description': description,\n",
    "    'parameters': {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The names of the relevant tools to use\",\n",
    "                \"enum\": []\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"name\"]}\n",
    "    }\n",
    "tool_names = [tool['name'] for tool in tools]\n",
    "tool_names.append(\"none\")\n",
    "meta_tool[\"parameters\"][\"properties\"][\"name\"][\"enum\"] = tool_names\n",
    "meta_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_meta_tool_system_prompt\n",
    "tools_schema = tools_to_schema(tools)\n",
    "meta_tool_schema = tools_to_schema(meta_tool)\n",
    "tool_list_start=\"<tool>\",\n",
    "tool_list_end=\"</tools>\",\n",
    "tool_call_start=\"<tool_call>\",\n",
    "tool_call_end=\"</tool_call>\",\n",
    "tool_response_start=\"<tool_response>\",\n",
    "tool_response_end=\"</tool_response>\"\n",
    "\n",
    "\n",
    "_system_prompt = \"\"\"You are a function calling AI model. Your job is to answer the user's questions and you may call one or more functions to do this.\n",
    "\n",
    "\n",
    "Please use your own judgment as to whether or not you should call a function. In particular, you must follow these guiding principles:\n",
    "1. You may call one or more functions to assist with the user query. You should call multiple functions when the user asks you to.\n",
    "2. You do not need to call a function. If none of the functions can be used to answer the user's question, please do not make the function call.\n",
    "3. Don't make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters.\n",
    "4. You may assume the user has implemented the function themselves.\n",
    "5. You may assume the user will call the function on their own. You should NOT ask the user to call the function and let you know the result; they will do this on their own.\n",
    "6. Never call a tool twice with the same exact arguments. Do not repeat your tool calls!\n",
    "7. Only call tools that are relevant to the user's query. Do not call tools that are unrelated or will not help the user to answer the query.\n",
    "\n",
    "You can only call functions according the following formatting rules:\n",
    "Rule 1: All the functions you have access to are contained within {tool_list_start}{tool_list_end} XML tags. You cannot use any functions that are not listed between these tags.\n",
    "\n",
    "Rule 2: For each function call return a json object (using quotes) with function name and arguments within {tool_call_start}\\n{{ }}\\n{tool_call_end} XML tags as follows:\n",
    "* With arguments:\n",
    "{tool_call_start}\\n{{\"tool_name\": \"function_name\", \"tool_arguments\": {{\"argument_1_name\": \"value\", \"argument_2_name\": \"value\"}} }}\\n{tool_call_end}\n",
    "* Without arguments:\n",
    "{tool_call_start}\\n{{ \"tool_name\": \"function_name\", \"tool_arguments\": {{}} }}\\n{tool_call_end}\n",
    "In between {tool_call_start} and{tool_call_end} tags, you MUST respond in a valid JSON schema.\n",
    "In between the {tool_call_start} and {tool_call_end} tags you MUST only write in json; no other text is allowed.\n",
    "\n",
    "Rule 3: If user decides to run the function, they will output the result of the function call between the {tool_response_start} and {tool_response_end} tags. If it answers the user's question, you should incorporate the output of the function in your answer.\n",
    "\n",
    "\n",
    "You should first restate what the user wants you to do. Then plan out all the tools you want to call.\n",
    "More specifically, list out the tools you wish to call and the order you wish to call them in.\n",
    "Explain why you are calling each tool to justify it. Think step by step.\n",
    "\n",
    "\n",
    "Here are the tools available to you:\n",
    "{tool_list_start}\\n{tools_schema}\\n{tool_list_end}\n",
    "\n",
    "Output the name of the \"tool_name\" that you would want to call adherent to the following JSON format {meta_tool_schema}.\n",
    "Remember, if you do not want to call any tools, please use the \"none\" keyword. And write your tool within {tool_call_start}\\n{{ }}\\n{tool_call_end} XML tags.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = _system_prompt.format(\n",
    "    tool_list_start=tool_list_start,\n",
    "    tool_list_end=tool_list_end,\n",
    "    tool_call_start=tool_call_start,\n",
    "    tool_call_end=tool_call_end,\n",
    "    tool_response_start=tool_response_start,\n",
    "    tool_response_end=tool_response_end,\n",
    "    tools_schema=tools_schema,\n",
    "    meta_tool_schema=meta_tool_schema\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query:\n",
      "How to assess the population growth in deer and their impact on woodland in Washington state over the past decade?\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_query}]\n",
    "print(f\"User Query:\\n{user_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta tool generation\n",
    "output_messages, tool_calls = my_tool(messages, tools, gen_mode=\"meta_tool\", n_tool_calls=\"auto\")\n",
    "print(\"Meta Tool Generation:\")\n",
    "if tool_calls:\n",
    "    for tool_call in tool_calls: print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a function calling AI model. Your job is to answer the user\\'s questions and you may call one or more functions to do this.\\n\\n\\nPlease use your own judgment as to whether or not you should call a function. In particular, you must follow these guiding principles:\\n1. You may call one or more functions to assist with the user query. You should call multiple functions when the user asks you to.\\n2. You do not need to call a function. If none of the functions can be used to answer the user\\'s question, please do not make the function call.\\n3. Don\\'t make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters.\\n4. You may assume the user has implemented the function themselves.\\n5. You may assume the user will call the function on their own. You should NOT ask the user to call the function and let you know the result; they will do this on their own.\\n6. Never call a tool twice with the same exact arguments. Do not repeat your tool calls!\\n7. Only call tools that are relevant to the user\\'s query. Do not call tools that are unrelated or will not help the user to answer the query.\\n\\n\\nYou can only call functions according the following formatting rules:\\nRule 1: All the functions you have access to are contained within (\\'<tool>\\',)(\\'</tools>\\',) XML tags. You cannot use any functions that are not listed between these tags.\\n\\nRule 2: For each function call return a json object (using quotes) with function name and arguments within (\\'<tool_call>\\',)\\n{ }\\n(\\'</tool_call>\\',) XML tags as follows:\\n* With arguments:\\n(\\'<tool_call>\\',)\\n{\"tool_name\": \"function_name\", \"tool_arguments\": {\"argument_1_name\": \"value\", \"argument_2_name\": \"value\"} }\\n(\\'</tool_call>\\',)\\n* Without arguments:\\n(\\'<tool_call>\\',)\\n{ \"tool_name\": \"function_name\", \"tool_arguments\": {} }\\n(\\'</tool_call>\\',)\\nIn between (\\'<tool_call>\\',) and(\\'</tool_call>\\',) tags, you MUST respond in a valid JSON schema.\\nIn between the (\\'<tool_call>\\',) and (\\'</tool_call>\\',) tags you MUST only write in json; no other text is allowed.\\n\\nRule 3: If user decides to run the function, they will output the result of the function call between the (\\'<tool_response>\\',) and </tool_response> tags. If it answers the user\\'s question, you should incorporate the output of the function in your answer.\\n\\n\\nYou should first restate what the user wants you to do. Then plan out all the tools you want to call.\\nMore specifically, list out the tools you wish to call and the order you wish to call them in.\\nExplain why you are calling each tool to justify it. Think step by step.\\n\\n\\nHere are the tools available to you:\\n(\\'<tool>\\',)\\n{\"title\": \"wildlife_population.assess_growth\", \"type\": \"object\", \"description\": \"Assesses the population growth of a specific species in a specified location over a period.\", \"properties\": {\"species\": {\"type\": \"string\", \"description\": \"The species for which the growth is to be calculated.\"}, \"location\": {\"type\": \"string\", \"description\": \"The area where the species is present.\"}, \"duration\": {\"type\": \"integer\", \"description\": \"The time period for which the population growth should be calculated in years.\"}}, \"required\": [\"species\", \"location\", \"duration\"]}\\n{\"title\": \"ecological_impact.analyze\", \"type\": \"object\", \"description\": \"Analyzes the impact of a species on a particular ecosystem.\", \"properties\": {\"species\": {\"type\": \"string\", \"description\": \"The species whose impact is to be calculated.\"}, \"ecosystem\": {\"type\": \"string\", \"description\": \"The ecosystem being affected.\"}, \"location\": {\"type\": \"string\", \"description\": \"The area where the impact is analyzed.\"}, \"timeframe\": {\"type\": \"integer\", \"description\": \"The time period for which the impact analysis should be carried out in years.\", \"default\": 5}}, \"required\": [\"species\", \"ecosystem\", \"location\"]}\\n(\\'</tools>\\',)\\n\\nOutput the name of the \"tool_name\" that you would want to call adherent to the following JSON format {\"title\": \"pick_relevant_tool\", \"type\": \"object\", \"description\": \"Pick\\'s the relevant tool that corresponds to user\\'s query.Choose the \\\\\"none\\\\\" keyword if none of the tools are relevant to the user\\'s query. If you have already called a tool, choose the `none` argument. Do not repeat a tool call!\", \"properties\": {\"name\": {\"type\": \"string\", \"description\": \"The names of the relevant tools to use\", \"enum\": [\"wildlife_population.assess_growth\", \"ecological_impact.analyze\", \"none\"]}}, \"required\": [\"name\"]}.\\nRemember, if you do not want to call any tools, please use the \"none\" keyword. And write your tool within (\\'<tool_call>\\',)\\n{ }\\n(\\'</tool_call>\\',) XML tags.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': 'How to assess the population growth in deer and their impact on woodland in Washington state over the past decade?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<tool_call>{\"tool_name\": \"pick_relevant_tool\", \"tool_arguments\": {\"name\": \"wildlife_population.assess_growth\"}}</tool_call>'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<tool_call>{\"tool_name\": \"wildlife_population.assess_growth\", \"tool_arguments\": {\"species\": \"deer\", \"location\": \"Washington state\", \"duration\": 10}}</tool_call>\\n'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<tool_call>{\"tool_name\": \"pick_relevant_tool\", \"tool_arguments\": {\"name\": \"ecological_impact.analyze\"}}</tool_call>'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<tool_call>{\"tool_name\": \"ecological_impact.analyze\", \"tool_arguments\": {\"species\": \"deer\", \"ecosystem\": \"woodland\", \"location\": \"Washington state\", \"timeframe\": 10}}</tool_call>\\n'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<tool_call>{\"tool_name\": \"pick_relevant_tool\", \"tool_arguments\": {\"name\": \"none\"}}</tool_call>'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'To answer your question, I will first call the \"wildlife_population.assess_growth\" tool to assess the population growth of deer in Washington state over the past decade. Then, I will call the \"ecological_impact.analyze\" tool to analyze the impact of deer on the woodland ecosystem in Washington state over the same time period. I will not call any other tools as they are not relevant to your query.\\n\\n<tool_call>{\"tool_name\": \"wildlife_population.assess_growth\", \"tool_arguments\": {\"species\": \"deer\", \"location\": \"Washington state\", \"duration\": 10}}</tool_call>\\n<tool_call>{\"tool_name\": \"ecological_impact.analyze\", \"tool_arguments\": {\"species\": \"deer\", \"ecosystem\": \"woodland\", \"location\": \"Washington state\", \"timeframe\": 10}}</tool_call>\\n<tool_call>{\"tool_name\": \"pick_relevant_tool\", \"tool_arguments\": {\"name\": \"none\"}}</tool_call>'}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gorilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
