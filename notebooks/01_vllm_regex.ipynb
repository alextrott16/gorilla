{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "from openai import OpenAI\n",
    "from outlines.fsm.json_schema import build_regex_from_schema, get_schema_from_signature\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x7f885023b460>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"-\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool To Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_or(pattern1, pattern2):\n",
    "    return f\"(?:{pattern1}|{pattern2})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sometime_guide(regex_pattern, start_guided_pattern=\"<tool_call>\", end_guided_pattern=\"</tool_call>\"):\n",
    "    \"\"\"\n",
    "    Only do guided generation sometimes, in between start_word and end_word.\n",
    "    \"\"\"\n",
    "    return f\".*?(?={start_guided_pattern}){start_guided_pattern}({regex_pattern}).*?(?={end_guided_pattern}){end_guided_pattern}.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bfcl(tool):\n",
    "    return isinstance(tool, dict) and list(tool.keys()) == ['name', 'description', 'parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_to_regex(tool, whitespace_pattern=None, test_category=None):\n",
    "\n",
    "    if isinstance(tool, list):\n",
    "        values = [tool_to_regex(_tool, whitespace_pattern=whitespace_pattern, test_category=test_category) for _tool in tool]\n",
    "        regex_strs = [v[0] for v in values]\n",
    "        regex_str = reduce(regex_or, regex_strs)\n",
    "        schema_strs = [v[1] for v in values]\n",
    "        schema_str = \"\\n\".join(schema_strs)\n",
    "    elif is_bfcl(tool):\n",
    "        schema_str = bfcl_function_to_schema(tool, test_category).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{tool[\"name\"]}\", \"tool_arguments\": {schema_regex}}}'\n",
    "    elif isinstance(tool, type(BaseModel)):\n",
    "        schema_json = tool.model_json_schema()\n",
    "        schema_str = json.dumps(schema_json).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{schema_json[\"title\"]}\", \"tool_arguments\": {schema_regex}}}'\n",
    "    elif callable(tool):\n",
    "        schema_json = get_schema_from_signature(tool)\n",
    "        schema_str = json.dumps(schema_json).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{tool.__name__}\", \"tool_arguments\": {schema_regex}}}'\n",
    "    elif isinstance(tool, str):\n",
    "        schema_str = tool.replace(\"\\n\", \" \").replace(\"  \", \" \").strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{json.loads(schema_str)[\"title\"]}\", \"tool_arguments\": {schema_regex}}}'\n",
    "\n",
    "    return regex_str, schema_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?:(?:{\"tool_name\": \"add\", \"tool_arguments\": \\{[\\n ]*\"a\"[\\n ]*:[\\n ]*(0|[1-9][0-9]*)[\\n ]*,[\\n ]*\"b\"[\\n ]*:[\\n ]*(0|[1-9][0-9]*)[\\n ]*\\}}|{\"tool_name\": \"User\", \"tool_arguments\": \\{[\\n ]*\"name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,[\\n ]*\"last_name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,[\\n ]*\"id\"[\\n ]*:[\\n ]*(0|[1-9][0-9]*)[\\n ]*\\}})|{\"tool_name\": \"User\", \"tool_arguments\": \\{([\\n ]*\"name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"([\\n ]*,[\\n ]*\"last_name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\")?([\\n ]*,[\\n ]*\"id\"[\\n ]*:[\\n ]*(0|[1-9][0-9]*))?|([\\n ]*\"name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,)?[\\n ]*\"last_name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"([\\n ]*,[\\n ]*\"id\"[\\n ]*:[\\n ]*(0|[1-9][0-9]*))?|([\\n ]*\"name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,)?([\\n ]*\"last_name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,)?[\\n ]*\"id\"[\\n ]*:[\\n ]*(0|[1-9][0-9]*))?[\\n ]*\\}})\n",
      "{\"properties\": {\"a\": {\"title\": \"A\", \"type\": \"integer\"}, \"b\": {\"title\": \"B\", \"type\": \"integer\"}}, \"required\": [\"a\", \"b\"], \"title\": \"Arguments\", \"type\": \"object\"}\n",
      "{\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"last_name\": {\"title\": \"Last Name\", \"type\": \"string\"}, \"id\": {\"title\": \"Id\", \"type\": \"integer\"}}, \"required\": [\"name\", \"last_name\", \"id\"], \"title\": \"User\", \"type\": \"object\"}\n",
      "{  \"title\": \"User\",  \"type\": \"object\",  \"properties\": {   \"name\": {\"type\": \"string\"},   \"last_name\": {\"type\": \"string\"},   \"id\": {\"type\": \"integer\"}  } }\n"
     ]
    }
   ],
   "source": [
    "def add(a: int, b: int):\n",
    "    return a+b\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    last_name: str\n",
    "    id: int\n",
    "\n",
    "schema = \"\"\"\n",
    "{\n",
    "  \"title\": \"User\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"name\": {\"type\": \"string\"},\n",
    "    \"last_name\": {\"type\": \"string\"},\n",
    "    \"id\": {\"type\": \"integer\"}\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "tools = [add, User, schema]\n",
    "regex_str, tool_schema = tool_to_regex(tools)\n",
    "print(regex_str)\n",
    "print(schema_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(\n",
    "    tool_schema,\n",
    "    tool_list_start=\"<tool>\",\n",
    "    tool_list_end=\"</tools>\",\n",
    "    tool_call_start=\"<tool_call>\",\n",
    "    tool_call_end=\"</tool_call>\",\n",
    "    tool_response_start=\"<tool_response>\",\n",
    "    tool_response_end=\"</tool_response>\"\n",
    "    ):\n",
    "\n",
    "    system_prompt = \"\"\"You are a function calling AI model. Your job is to answer the user's questions and you may call one or more functions to do this.\n",
    "\n",
    "\n",
    "    Please use your own judgment as to whether or not you should call a function. In particular, you must follow these guiding principles:\n",
    "    1. You may call one or more functions to assist with the user query.\n",
    "    2. You do not need to call a function. If none of the functions can be used to answer the user's question, please do not make the function call.\n",
    "    3. Don't make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters.\n",
    "    4. You may assume the user has implemented the function themselves.\n",
    "    5. You may assume the user will call the function on their own. You should NOT ask the user to call the function and let you know the result; they will do this on their own.\n",
    "\n",
    "\n",
    "    You can only call functions according the following formatting rules:\n",
    "    Rule 1: All the functions you have access to are contained within {tool_list_start}{tool_list_end} XML tags. You cannot use any functions that are not listed between these tags.\n",
    "\n",
    "    Rule 2: For each function call return a json object (using quotes) with function name and arguments within {tool_call_start}\\n{{ }}\\n{tool_call_end} XML tags as follows:\n",
    "    * With arguments:\n",
    "    {tool_call_start}\\n{{\"name\": \"function_name\", \"arguments\": {{\"argument_1_name\": \"value\", \"argument_2_name\": \"value\"}} }}\\n{tool_call_end}\n",
    "    * Without arguments:\n",
    "    {tool_call_start}\\n{{ \"name\": \"function_name\", \"arguments\": {{}} }}\\n{tool_call_end}\n",
    "    In between {tool_call_start} and{tool_call_end} tags, you MUST respond in a valid JSON schema.\n",
    "    In between the {tool_call_start} and {tool_call_end} tags you MUST only write in json; no other text is allowed.\n",
    "\n",
    "    Rule 3: If user decides to run the function, they will output the result of the function call between the {tool_response_start} and {tool_response_start} tags. If it answers the user's question, you should incorporate the output of the function in your answer.\n",
    "\n",
    "\n",
    "    Here are the tools available to you:\n",
    "    {tool_list_start}\\n{tool_schema}\\n{tool_list_end}\n",
    "\n",
    "    Remember, don't make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters. Do not be afraid to ask.\n",
    "    \"\"\"\n",
    "\n",
    "    return system_prompt.format(\n",
    "        tool_list_start=tool_list_start,\n",
    "        tool_list_end=tool_list_end,\n",
    "        tool_call_start=tool_call_start,\n",
    "        tool_call_end=tool_call_end,\n",
    "        tool_response_start=tool_response_start,\n",
    "        tool_response_end=tool_response_end,\n",
    "        tool_schema=tool_schema,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2401256792.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    {\"role\": \"system\", \"content\": system_prompt}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Classify this sentiment: vLLM is wonderful!\"\n",
    "system_prompt = get_system_prompt(tool_schema)\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt}\n",
    "    {\"role\": \"user\", \"content\": user_query}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"databricks/dbrx-instruct\",\n",
    "  messages=messages,\n",
    "  #extra_body=dict(guided_regex=TEST_REGEX, guided_decoding_backend=\"outlines\"),\n",
    "  )\n",
    "\n",
    "raw_text = completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gorilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
