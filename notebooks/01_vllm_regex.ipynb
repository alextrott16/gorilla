{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export HF_HUB_ENABLE_HF_TRANSFER=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from functools import reduce\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "from outlines import models, generate\n",
    "from outlines.fsm.json_schema import build_regex_from_schema, get_schema_from_signature\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"transformers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/utils/modeling.py:1363: UserWarning: Current model requires 486542976 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e098f11c5254641a9538377ff3f2b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 39.39 GiB of which 7.31 MiB is free. Process 1348381 has 7.86 GiB memory in use. Process 3128825 has 14.97 GiB memory in use. Process 3186877 has 14.98 GiB memory in use. Process 3371963 has 1.55 GiB memory in use. Of the allocated memory 1.04 GiB is allocated by PyTorch, and 105.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m chat_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m bos_token }}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m% f\u001b[39;00m\u001b[38;5;124mor message in messages \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m% i\u001b[39;00m\u001b[38;5;124mf message[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[INST] \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m + message[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] + \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m }}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m% e\u001b[39;00m\u001b[38;5;124mlse \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m + message[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] + eos_token}}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m% e\u001b[39;00m\u001b[38;5;124mndif \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m% e\u001b[39;00m\u001b[38;5;124mndfor \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mchat_template \u001b[38;5;241m=\u001b[39m chat_template\n\u001b[0;32m----> 9\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mTransformers(llm, tokenizer)\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/transformers/modeling_utils.py:3589\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3587\u001b[0m         device_map_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_keys\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_skip_keys_device_placement\n\u001b[1;32m   3588\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_deepspeed_zero3_enabled():\n\u001b[0;32m-> 3589\u001b[0m         \u001b[43mdispatch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdevice_map_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3592\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mpostprocess_model(model)\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/big_modeling.py:419\u001b[0m, in \u001b[0;36mdispatch_model\u001b[0;34m(model, device_map, main_device, state_dict, offload_dir, offload_index, offload_buffers, skip_keys, preload_module_classes, force_hooks)\u001b[0m\n\u001b[1;32m    414\u001b[0m         tied_params_map[data_ptr] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;66;03m# Note: To handle the disk offloading case, we can not simply use weights_map[param_name].data_ptr() as the reference pointer,\u001b[39;00m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;66;03m# as we have no guarantee that safetensors' `file.get_tensor()` will always give the same pointer.\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m \u001b[43mattach_align_device_hook_on_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# warn if there is any params on the meta device\u001b[39;00m\n\u001b[1;32m    431\u001b[0m offloaded_devices_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    432\u001b[0m     [device \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m    433\u001b[0m )\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/hooks.py:648\u001b[0m, in \u001b[0;36mattach_align_device_hook_on_blocks\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes, tied_params_map)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    647\u001b[0m     child_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(module_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m child_name\n\u001b[0;32m--> 648\u001b[0m     \u001b[43mattach_align_device_hook_on_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchild_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/hooks.py:648\u001b[0m, in \u001b[0;36mattach_align_device_hook_on_blocks\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes, tied_params_map)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    647\u001b[0m     child_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(module_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m child_name\n\u001b[0;32m--> 648\u001b[0m     \u001b[43mattach_align_device_hook_on_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchild_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/hooks.py:648\u001b[0m, in \u001b[0;36mattach_align_device_hook_on_blocks\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes, tied_params_map)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    647\u001b[0m     child_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(module_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m child_name\n\u001b[0;32m--> 648\u001b[0m     \u001b[43mattach_align_device_hook_on_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchild_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/hooks.py:611\u001b[0m, in \u001b[0;36mattach_align_device_hook_on_blocks\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes, tied_params_map)\u001b[0m\n\u001b[1;32m    609\u001b[0m     attach_execution_device_hook(module, execution_device[module_name], tied_params_map\u001b[38;5;241m=\u001b[39mtied_params_map)\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m module_name \u001b[38;5;129;01min\u001b[39;00m execution_device \u001b[38;5;129;01mand\u001b[39;00m module_name \u001b[38;5;129;01min\u001b[39;00m offload:\n\u001b[0;32m--> 611\u001b[0m     \u001b[43mattach_align_device_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hf_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    623\u001b[0m         hook \u001b[38;5;241m=\u001b[39m AlignDevicesHook(\n\u001b[1;32m    624\u001b[0m             execution_device\u001b[38;5;241m=\u001b[39mexecution_device[module_name],\n\u001b[1;32m    625\u001b[0m             io_same_device\u001b[38;5;241m=\u001b[39m(module_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    626\u001b[0m             skip_keys\u001b[38;5;241m=\u001b[39mskip_keys,\n\u001b[1;32m    627\u001b[0m             tied_params_map\u001b[38;5;241m=\u001b[39mtied_params_map,\n\u001b[1;32m    628\u001b[0m         )\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/hooks.py:504\u001b[0m, in \u001b[0;36mattach_align_device_hook\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes, tied_params_map)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    503\u001b[0m     child_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(module_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m child_name\n\u001b[0;32m--> 504\u001b[0m     \u001b[43mattach_align_device_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchild_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/hooks.py:504\u001b[0m, in \u001b[0;36mattach_align_device_hook\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes, tied_params_map)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    503\u001b[0m     child_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(module_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m child_name\n\u001b[0;32m--> 504\u001b[0m     \u001b[43mattach_align_device_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchild_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_module_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_module_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/hooks.py:495\u001b[0m, in \u001b[0;36mattach_align_device_hook\u001b[0;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, skip_keys, preload_module_classes, tied_params_map)\u001b[0m\n\u001b[1;32m    485\u001b[0m         prefixed_weights_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     hook \u001b[38;5;241m=\u001b[39m AlignDevicesHook(\n\u001b[1;32m    487\u001b[0m         execution_device\u001b[38;5;241m=\u001b[39mexecution_device,\n\u001b[1;32m    488\u001b[0m         offload\u001b[38;5;241m=\u001b[39moffload,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    493\u001b[0m         tied_params_map\u001b[38;5;241m=\u001b[39mtied_params_map,\n\u001b[1;32m    494\u001b[0m     )\n\u001b[0;32m--> 495\u001b[0m     \u001b[43madd_hook_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# We stop the recursion in case we hit the full offload.\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_offload:\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/hooks.py:157\u001b[0m, in \u001b[0;36madd_hook_to_module\u001b[0;34m(module, hook, append)\u001b[0m\n\u001b[1;32m    154\u001b[0m     old_forward \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mforward\n\u001b[1;32m    155\u001b[0m     module\u001b[38;5;241m.\u001b[39m_old_forward \u001b[38;5;241m=\u001b[39m old_forward\n\u001b[0;32m--> 157\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m module\u001b[38;5;241m.\u001b[39m_hf_hook \u001b[38;5;241m=\u001b[39m hook\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/hooks.py:304\u001b[0m, in \u001b[0;36mAlignDevicesHook.init_hook\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffload_buffers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_buffers(recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_submodules):\n\u001b[0;32m--> 304\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffload_buffers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m get_non_persistent_buffers(module, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_submodules):\n",
      "File \u001b[0;32m/mnt/workdisk/eitan/venvs/gorilla-5/lib/python3.11/site-packages/accelerate/utils/modeling.py:391\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mold_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)]:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(old_value\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mstartswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.uint\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.int\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 39.39 GiB of which 7.31 MiB is free. Process 1348381 has 7.86 GiB memory in use. Process 3128825 has 14.97 GiB memory in use. Process 3186877 has 14.98 GiB memory in use. Process 3371963 has 1.55 GiB memory in use. Of the allocated memory 1.04 GiB is allocated by PyTorch, and 105.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "if mode == \"vllm-endpoint\":\n",
    "    client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"-\")\n",
    "elif mode == \"transformers\":\n",
    "    token = \"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\"\n",
    "    model_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, token=token)\n",
    "    chat_template = \"{{ bos_token }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '\\n[INST] ' + message['content'] + ' [/INST]' }}{% else %}{{ '\\n' + message['content'] + eos_token}}{% endif %}{% endfor %}\"\n",
    "    tokenizer.chat_template = chat_template\n",
    "    llm = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        output_attentions=True,\n",
    "        token=token,\n",
    "    )\n",
    "    model = models.Transformers(llm, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool To Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_or(pattern1, pattern2):\n",
    "    return f\"(?:{pattern1}|{pattern2})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sometime_guide(regex_pattern, start_guided_pattern=\"<tool_call>\", end_guided_pattern=\"</tool_call>\"):\n",
    "    \"\"\"\n",
    "    Only do guided generation sometimes, i.e. only force us to output according to the regex pattern in between start_word and end_word.\n",
    "    \"\"\"\n",
    "    return f\".*?(?={start_guided_pattern}){start_guided_pattern}({regex_pattern}).*?(?={end_guided_pattern}){end_guided_pattern}.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bfcl(tool):\n",
    "    return isinstance(tool, dict) and list(tool.keys()) == ['name', 'description', 'parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_pattern(pattern, num_repeats):\n",
    "    \"\"\"Repeat the regex pattern `pattern` `num_repeats` times.\n",
    "\n",
    "    If `num_repeats` is `None`, allow the pattern to be repeated an unlimited number of times.\n",
    "    If `num_repeats` is an integer, repeat the pattern exactly `num` times.\n",
    "    If `num_repeats` is an iterable with length two, repeat the pattern anywhere between `num[0]` and `num[1]` times, inclusive.\n",
    "    \"\"\"\n",
    "    s\n",
    "    if num_repeats is None:\n",
    "        result = f\"({pattern})*\"\n",
    "    elif isinstance(num_repeats, int):\n",
    "        result = f\"({pattern}){{{num_repeats}}}\"\n",
    "    elif isinstance(num_repeats, Union[list, tuple, set]) and len(num_repeats) == 2:\n",
    "        return f\"({pattern}){{{num_repeats[0]},{num_repeats[1]}}}\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_to_regex(\n",
    "    tool,\n",
    "    n_tool_calls=1,\n",
    "    start_guided_pattern=\"<tool_call>\",\n",
    "    end_guided_pattern=\"</tool_call>\",\n",
    "    sometimes=False,\n",
    "    whitespace_pattern=None,\n",
    "    test_category=None,\n",
    "    ):\n",
    "\n",
    "    if isinstance(tool, list):\n",
    "        values = [\n",
    "            tool_to_regex(_tool, n_tool_calls=n_tool_calls, start_guided_pattern=start_guided_pattern, end_guided_pattern=end_guided_pattern, sometimes=sometimes, whitespace_pattern=whitespace_pattern, test_category=test_category,)\n",
    "            for _tool in tool\n",
    "            ]\n",
    "        regex_strs, schema_strs = [v[0] for v in values], [v[1] for v in values]\n",
    "        regex_str = reduce(regex_or, regex_strs)\n",
    "        schema_str = \"\\n\".join(schema_strs)\n",
    "    elif is_bfcl(tool):\n",
    "        schema_str = bfcl_function_to_schema(tool, test_category).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{tool[\"name\"]}\", \"tool_arguments\": {schema_regex}}}'\n",
    "    elif isinstance(tool, type(BaseModel)):\n",
    "        schema_json = tool.model_json_schema()\n",
    "        schema_str = json.dumps(schema_json).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{schema_json[\"title\"]}\", \"tool_arguments\": {schema_regex}}}'\n",
    "    elif callable(tool):\n",
    "        schema_json = get_schema_from_signature(tool)\n",
    "        schema_str = json.dumps(schema_json).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{tool.__name__}\", \"tool_arguments\": {schema_regex}}}'\n",
    "    elif isinstance(tool, str):\n",
    "        schema_str = re.sub(r'\\s+', ' ', tool).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{json.loads(schema_str)[\"title\"]}\", \"tool_arguments\": {schema_regex}}}'\n",
    "\n",
    "    # if sometimes:\n",
    "    #     regex_str = sometime_guide(regex_str)\n",
    "    # elif not isinstance(tool, list):\n",
    "    #     regex_str = f\"{start_guided_pattern}{regex_str}{end_guided_pattern}\"\n",
    "\n",
    "    if not isinstance(tool, list):\n",
    "        regex_str = repeat_pattern(regex_str, n_tool_calls)\n",
    "\n",
    "    return regex_str, schema_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(\n",
    "    tool_schema,\n",
    "    tool_list_start=\"<tool>\",\n",
    "    tool_list_end=\"</tools>\",\n",
    "    tool_call_start=\"<tool_call>\",\n",
    "    tool_call_end=\"</tool_call>\",\n",
    "    tool_response_start=\"<tool_response>\",\n",
    "    tool_response_end=\"</tool_response>\"\n",
    "    ):\n",
    "\n",
    "    system_prompt = \"\"\"You are a function calling AI model. Your job is to answer the user's questions and you may call one or more functions to do this.\n",
    "\n",
    "\n",
    "    Please use your own judgment as to whether or not you should call a function. In particular, you must follow these guiding principles:\n",
    "    1. You may call one or more functions to assist with the user query. You should call multiple functions when the user asks you to.\n",
    "    2. You do not need to call a function. If none of the functions can be used to answer the user's question, please do not make the function call.\n",
    "    3. Don't make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters.\n",
    "    4. You may assume the user has implemented the function themselves.\n",
    "    5. You may assume the user will call the function on their own. You should NOT ask the user to call the function and let you know the result; they will do this on their own.\n",
    "\n",
    "\n",
    "    You can only call functions according the following formatting rules:\n",
    "    Rule 1: All the functions you have access to are contained within {tool_list_start}{tool_list_end} XML tags. You cannot use any functions that are not listed between these tags.\n",
    "\n",
    "    Rule 2: For each function call return a json object (using quotes) with function name and arguments within {tool_call_start}\\n{{ }}\\n{tool_call_end} XML tags as follows:\n",
    "    * With arguments:\n",
    "    {tool_call_start}\\n{{\"tool_name\": \"function_name\", \"tool_arguments\": {{\"argument_1_name\": \"value\", \"argument_2_name\": \"value\"}} }}\\n{tool_call_end}\n",
    "    * Without arguments:\n",
    "    {tool_call_start}\\n{{ \"tool_name\": \"function_name\", \"tool_arguments\": {{}} }}\\n{tool_call_end}\n",
    "    In between {tool_call_start} and{tool_call_end} tags, you MUST respond in a valid JSON schema.\n",
    "    In between the {tool_call_start} and {tool_call_end} tags you MUST only write in json; no other text is allowed.\n",
    "\n",
    "    Rule 3: If user decides to run the function, they will output the result of the function call between the {tool_response_start} and {tool_response_start} tags. If it answers the user's question, you should incorporate the output of the function in your answer.\n",
    "\n",
    "\n",
    "    Here are the tools available to you:\n",
    "    {tool_list_start}\\n{tool_schema}\\n{tool_list_end}\n",
    "\n",
    "    Remember, don't make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters. Do not be afraid to ask.\n",
    "    \"\"\"\n",
    "\n",
    "    return system_prompt.format(\n",
    "        tool_list_start=tool_list_start,\n",
    "        tool_list_end=tool_list_end,\n",
    "        tool_call_start=tool_call_start,\n",
    "        tool_call_end=tool_call_end,\n",
    "        tool_response_start=tool_response_start,\n",
    "        tool_response_end=tool_response_end,\n",
    "        tool_schema=tool_schema,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tool(text):\n",
    "    return \"<tool_call>\" in text and \"</tool_call>\" in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tool(text):\n",
    "    \"\"\"Return a list of all tools that match the tool_regex and is independent of `tool_call_start` and `tool_call_end`. This works for multiple functions.\n",
    "    This works \"\"\"\n",
    "\n",
    "    tool_regex = r'\\{\"tool_name\": \"([^\"]+)\", \"tool_arguments\": (\\{[^{}]*\\})\\}'\n",
    "    matches = re.findall(tool_regex, text)\n",
    "    tool_calls = []\n",
    "    for match in matches:\n",
    "        tool_name = match[0]\n",
    "        tool_arguments = json.loads(match[1])\n",
    "        tool_calls.append({'tool_name': tool_name, 'tool_arguments': tool_arguments})\n",
    "    return tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfcl_format(tools):\n",
    "    tool_strs = []\n",
    "    for tool in tools:\n",
    "        args_string = ', '.join([f\"{key}='{value}'\" if isinstance(value, str) else f\"{key}={value}\" for key, value in tool[\"tool_arguments\"].items()])\n",
    "        tool_str = f'{tool[\"tool_name\"]}({args_string})'\n",
    "        tool_strs.append(tool_str)\n",
    "    result = '[' + ', '.join(tool_strs) + ']'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate  Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(mode, messages, regex_str, max_tokens=500, verbose=0):\n",
    "\n",
    "  if mode == \"vllm-endpoint\":\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"databricks/dbrx-instruct\",\n",
    "      max_tokens=max_tokens,\n",
    "      messages=messages,\n",
    "      extra_body=dict(guided_regex=regex_str, guided_decoding_backend=\"outlines\"),\n",
    "      )\n",
    "    raw_text = completion.choices[0].message.content\n",
    "  elif mode == \"transformers\":\n",
    "\n",
    "    if verbose >= 1:\n",
    "      print(\"Creating Generator Index...\", end=\"\\t\")\n",
    "\n",
    "    generator = generate.regex(model, regex_str)\n",
    "    generator.format_sequence = lambda x: x #json.loads(x)\n",
    "\n",
    "    if verbose >= 1:\n",
    "      print(\"Done\\nGenerating Text...\", end=\"\\t\")\n",
    "\n",
    "    rng_seed = 420\n",
    "    rng = torch.Generator(device=\"cuda\")\n",
    "    rng.manual_seed(rng_seed)\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    raw_text = generator(prompt, rng=rng, max_tokens=max_tokens)\n",
    "\n",
    "    if verbose >= 1:\n",
    "      print(\"Done\")\n",
    "\n",
    "  return raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex:\n",
      " (?:(?:({\"tool_name\": \"send_email\", \"tool_arguments\": \\{[\\n ]*\"sender\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,[\\n ]*\"recipient\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,[\\n ]*\"message\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*\\}}){1,10}|({\"tool_name\": \"User\", \"tool_arguments\": \\{[\\n ]*\"name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,[\\n ]*\"email\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*\\}}){1,10})|({\"tool_name\": \"User\", \"tool_arguments\": \\{([\\n ]*\"name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"([\\n ]*,[\\n ]*\"last_name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\")?([\\n ]*,[\\n ]*\"id\"[\\n ]*:[\\n ]*(-)?(0|[1-9][0-9]*))?|([\\n ]*\"name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,)?[\\n ]*\"last_name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"([\\n ]*,[\\n ]*\"id\"[\\n ]*:[\\n ]*(-)?(0|[1-9][0-9]*))?|([\\n ]*\"name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,)?([\\n ]*\"last_name\"[\\n ]*:[\\n ]*\"(?:[^\"\\\\\\x00-\\x1f\\x7f-\\x9f]|\\\\.)*\"[\\n ]*,)?[\\n ]*\"id\"[\\n ]*:[\\n ]*(-)?(0|[1-9][0-9]*))?[\\n ]*\\}}){1,10})\n",
      "\n",
      "Schemas:\n",
      " {\"properties\": {\"sender\": {\"title\": \"Sender\", \"type\": \"string\"}, \"recipient\": {\"title\": \"Recipient\", \"type\": \"string\"}, \"message\": {\"title\": \"Message\", \"type\": \"string\"}}, \"required\": [\"sender\", \"recipient\", \"message\"], \"title\": \"Arguments\", \"type\": \"object\"}\n",
      "{\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"email\": {\"title\": \"Email\", \"type\": \"string\"}}, \"required\": [\"name\", \"email\"], \"title\": \"User\", \"type\": \"object\"}\n",
      "{ \"title\": \"User\", \"type\": \"object\", \"properties\": { \"name\": {\"type\": \"string\"}, \"last_name\": {\"type\": \"string\"}, \"id\": {\"type\": \"integer\"} } }\n"
     ]
    }
   ],
   "source": [
    "def send_email(sender: str, recipient: str, message: str):\n",
    "    return \"Hi\"\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "\n",
    "schema = \"\"\"\n",
    "{\n",
    "  \"title\": \"User\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"name\": {\"type\": \"string\"},\n",
    "    \"last_name\": {\"type\": \"string\"},\n",
    "    \"id\": {\"type\": \"integer\"}\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "tools = [send_email, User, schema]\n",
    "regex_str, tool_schema = tool_to_regex(tools, n_tool_calls=(1, 10))\n",
    "\n",
    "\n",
    "print(\"Regex:\\n\", regex_str, end=\"\\n\\n\")\n",
    "print(\"Schemas:\\n\", tool_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a function calling AI model. Your job is to answer the user\\'s questions and you may call one or more functions to do this.\\n\\n\\n    Please use your own judgment as to whether or not you should call a function. In particular, you must follow these guiding principles:\\n    1. You may call one or more functions to assist with the user query. You should call multiple functions when the user asks you to.\\n    2. You do not need to call a function. If none of the functions can be used to answer the user\\'s question, please do not make the function call.\\n    3. Don\\'t make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters.\\n    4. You may assume the user has implemented the function themselves.\\n    5. You may assume the user will call the function on their own. You should NOT ask the user to call the function and let you know the result; they will do this on their own.\\n\\n\\n    You can only call functions according the following formatting rules:\\n    Rule 1: All the functions you have access to are contained within <tool></tools> XML tags. You cannot use any functions that are not listed between these tags.\\n\\n    Rule 2: For each function call return a json object (using quotes) with function name and arguments within <tool_call>\\n{ }\\n</tool_call> XML tags as follows:\\n    * With arguments:\\n    <tool_call>\\n{\"tool_name\": \"function_name\", \"tool_arguments\": {\"argument_1_name\": \"value\", \"argument_2_name\": \"value\"} }\\n</tool_call>\\n    * Without arguments:\\n    <tool_call>\\n{ \"tool_name\": \"function_name\", \"tool_arguments\": {} }\\n</tool_call>\\n    In between <tool_call> and</tool_call> tags, you MUST respond in a valid JSON schema.\\n    In between the <tool_call> and </tool_call> tags you MUST only write in json; no other text is allowed.\\n\\n    Rule 3: If user decides to run the function, they will output the result of the function call between the <tool_response> and <tool_response> tags. If it answers the user\\'s question, you should incorporate the output of the function in your answer.\\n\\n\\n    Here are the tools available to you:\\n    <tool>\\n{\"properties\": {\"sender\": {\"title\": \"Sender\", \"type\": \"string\"}, \"recipient\": {\"title\": \"Recipient\", \"type\": \"string\"}, \"message\": {\"title\": \"Message\", \"type\": \"string\"}}, \"required\": [\"sender\", \"recipient\", \"message\"], \"title\": \"Arguments\", \"type\": \"object\"}\\n{\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"email\": {\"title\": \"Email\", \"type\": \"string\"}}, \"required\": [\"name\", \"email\"], \"title\": \"User\", \"type\": \"object\"}\\n{ \"title\": \"User\", \"type\": \"object\", \"properties\": { \"name\": {\"type\": \"string\"}, \"last_name\": {\"type\": \"string\"}, \"id\": {\"type\": \"integer\"} } }\\n</tools>\\n\\n    Remember, don\\'t make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters. Do not be afraid to ask.\\n    '}\n",
      "{'role': 'user', 'content': 'And can you also make two user profiles, one for Alice (alice@gmail.com) and one for Bob (bob@databricks.com)? Use multiple function calls.'}\n"
     ]
    }
   ],
   "source": [
    "# user_query = \"Can you send an email from Alice (alice@gmail.com) to Bob (bob@databricks.com) saying 'We cracked the code!'? And can you also make two user profiles, one for Alice and one for Bob?\"\n",
    "user_query = \"And can you also make two user profiles, one for Alice (alice@gmail.com) and one for Bob (bob@databricks.com)?\"\n",
    "\n",
    "system_prompt = get_system_prompt(tool_schema)\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_query}\n",
    "  ]\n",
    "\n",
    "for message in messages:\n",
    "  print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Generator Index...\tDone\n",
      "Generating Text...\tDone\n",
      "{\"tool_name\": \"User\", \"tool_arguments\": {\"name\": \"Alice\", \"email\": \"alice@gmail.com\"}}\n"
     ]
    }
   ],
   "source": [
    "text = generate_text(mode, messages, regex_str, verbose=1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool_name': 'User', 'tool_arguments': {'name': 'Alice', 'email': 'alice@gmail.com'}}, {'tool_name': 'User', 'tool_arguments': {'name': 'Bob', 'email': 'bob@databricks.com'}}]\n"
     ]
    }
   ],
   "source": [
    "tool = parse_tool(text)\n",
    "print(tool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gorilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
