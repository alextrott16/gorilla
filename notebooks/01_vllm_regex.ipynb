{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export HF_HUB_ENABLE_HF_TRANSFER=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venvs/gorilla/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from functools import reduce\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "from outlines import models, generate\n",
    "from outlines.fsm.json_schema import build_regex_from_schema, get_schema_from_signature\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"vllm-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"vllm-endpoint\":\n",
    "    client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"-\")\n",
    "elif mode == \"transformers\":\n",
    "    token = \"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\"\n",
    "    model_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, token=token)\n",
    "    chat_template = \"{{ bos_token }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '\\n[INST] ' + message['content'] + ' [/INST]' }}{% else %}{{ '\\n' + message['content'] + eos_token}}{% endif %}{% endfor %}\"\n",
    "    tokenizer.chat_template = chat_template\n",
    "    llm = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        output_attentions=True,\n",
    "        token=token,\n",
    "    )\n",
    "    model = models.Transformers(llm, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool To Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GORILLA_TO_OPENAPI = {\n",
    "    \"integer\": \"integer\",\n",
    "    \"number\": \"number\",\n",
    "    \"float\": \"number\",\n",
    "    \"string\": \"string\",\n",
    "    \"boolean\": \"boolean\",\n",
    "    \"bool\": \"boolean\",\n",
    "    \"array\": \"array\",\n",
    "    \"list\": \"array\",\n",
    "    \"dict\": \"object\",\n",
    "    \"object\": \"object\",\n",
    "    \"tuple\": \"array\",\n",
    "    \"any\": \"string\",\n",
    "    \"byte\": \"integer\",\n",
    "    \"short\": \"integer\",\n",
    "    \"long\": \"integer\",\n",
    "    \"double\": \"number\",\n",
    "    \"char\": \"string\",\n",
    "    \"ArrayList\": \"array\",\n",
    "    \"Array\": \"array\",\n",
    "    \"HashMap\": \"object\",\n",
    "    \"Hashtable\": \"object\",\n",
    "    \"Queue\": \"array\",\n",
    "    \"Stack\": \"array\",\n",
    "    \"Any\": \"string\",\n",
    "    \"String\": \"string\",\n",
    "    \"Bigint\": \"integer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cast_to_openai_type(properties, mapping, test_category):\n",
    "    for key, value in properties.items():\n",
    "        if \"type\" not in value:\n",
    "            properties[key][\"type\"] = \"string\"\n",
    "        else:\n",
    "            var_type = value[\"type\"]\n",
    "            if mapping == GORILLA_TO_OPENAPI and var_type == \"float\":\n",
    "                properties[key][\"format\"] = \"float\"\n",
    "                properties[key][\"description\"] += \" This is a float type value.\"\n",
    "            if var_type in mapping:\n",
    "                properties[key][\"type\"] = mapping[var_type]\n",
    "            else:\n",
    "                properties[key][\"type\"] = \"string\"\n",
    "\n",
    "        # Currently support:\n",
    "        # - list of any\n",
    "        # - list of list of any\n",
    "        # - list of dict\n",
    "        # - list of list of dict\n",
    "        # - dict of any\n",
    "\n",
    "        if properties[key][\"type\"] == \"array\" or properties[key][\"type\"] == \"object\":\n",
    "            if \"properties\" in properties[key]:\n",
    "                properties[key][\"properties\"] = _cast_to_openai_type(\n",
    "                    properties[key][\"properties\"], mapping, test_category\n",
    "                )\n",
    "            elif \"items\" in properties[key]:\n",
    "                properties[key][\"items\"][\"type\"] = mapping[\n",
    "                    properties[key][\"items\"][\"type\"]\n",
    "                ]\n",
    "                if (\n",
    "                    properties[key][\"items\"][\"type\"] == \"array\"\n",
    "                    and \"items\" in properties[key][\"items\"]\n",
    "                ):\n",
    "                    properties[key][\"items\"][\"items\"][\"type\"] = mapping[\n",
    "                        properties[key][\"items\"][\"items\"][\"type\"]\n",
    "                    ]\n",
    "                elif (\n",
    "                    properties[key][\"items\"][\"type\"] == \"object\"\n",
    "                    and \"properties\" in properties[key][\"items\"]\n",
    "                ):\n",
    "                    properties[key][\"items\"][\"properties\"] = _cast_to_openai_type(\n",
    "                        properties[key][\"items\"][\"properties\"], mapping, test_category\n",
    "                    )\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfcl_function_to_schema(function, test_category):\n",
    "    properties = _cast_to_openai_type(function[\"parameters\"][\"properties\"], GORILLA_TO_OPENAPI, test_category)\n",
    "    schema = json.dumps({\n",
    "        \"title\": function[\"name\"],\n",
    "        \"type\": \"object\",\n",
    "        \"description\": function[\"description\"],\n",
    "        \"properties\": properties,\n",
    "        \"required\": function[\"parameters\"][\"required\"],\n",
    "        })\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_or(pattern1, pattern2):\n",
    "    return f\"(?:{pattern1}|{pattern2})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sometime_guide(regex_pattern, start_guided_pattern=\"<tool_call>\", end_guided_pattern=\"</tool_call>\"):\n",
    "    \"\"\"\n",
    "    Only do guided generation sometimes, i.e. only force us to output according to the regex pattern in between start_word and end_word.\n",
    "    \"\"\"\n",
    "    return f\".*?(?={start_guided_pattern}){start_guided_pattern}({regex_pattern}).*?(?={end_guided_pattern}){end_guided_pattern}.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bfcl(tool):\n",
    "    return isinstance(tool, dict) and list(tool.keys()) == ['name', 'description', 'parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_regex_pattern(pattern, num_repeats, sep=\"\\\\n\"):\n",
    "    \"\"\"Repeat the regex pattern `pattern` `num_repeats` times.\n",
    "\n",
    "    If `num_repeats` is `None`, allow the pattern to be repeated an unlimited number of times.\n",
    "    If `num_repeats` is an integer, repeat the pattern exactly `num` times.\n",
    "    If `num_repeats` is an iterable with length two, repeat the pattern anywhere between `num[0]` and `num[1]` times, inclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    if num_repeats is None:\n",
    "        min_repetitions = 0\n",
    "        max_repetitions = None\n",
    "    elif isinstance(num_repeats, int):\n",
    "        min_repetitions = max_repetitions = num_repeats\n",
    "    elif isinstance(num_repeats, Union[list, tuple, set]) and len(num_repeats) == 2:\n",
    "        min_repetitions = num_repeats[0]\n",
    "        max_repetitions = num_repeats[1]\n",
    "\n",
    "    if max_repetitions is None:\n",
    "        regex_str = f'({pattern}{sep}){{{min_repetitions},}}'\n",
    "    else:\n",
    "        regex_str = f'({pattern}{sep}){{{min_repetitions},{max_repetitions}}}'\n",
    "\n",
    "    return regex_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_to_regex(\n",
    "    tool,\n",
    "    n_tool_calls=1,\n",
    "    tool_call_start=\"<tool_call>\",\n",
    "    tool_call_end=\"</tool_call>\",\n",
    "    sometimes=False,\n",
    "    whitespace_pattern=None,\n",
    "    test_category=None,\n",
    "    ):\n",
    "\n",
    "    if isinstance(tool, list):\n",
    "        values = [\n",
    "            tool_to_regex(_tool, n_tool_calls=n_tool_calls, tool_call_start=tool_call_start, tool_call_end=tool_call_end, sometimes=sometimes, whitespace_pattern=whitespace_pattern, test_category=test_category,)\n",
    "            for _tool in tool\n",
    "            ]\n",
    "        regex_strs, schema_strs = [v[0] for v in values], [v[1] for v in values]\n",
    "        regex_str = reduce(regex_or, regex_strs)\n",
    "        schema_str = \"\\n\".join(schema_strs)\n",
    "    elif is_bfcl(tool):\n",
    "        schema_str = bfcl_function_to_schema(tool, test_category).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{tool[\"name\"]}\", \"tool_arguments\": {schema_regex}}}'\n",
    "    elif isinstance(tool, type(BaseModel)):\n",
    "        schema_json = tool.model_json_schema()\n",
    "        schema_str = json.dumps(schema_json).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{schema_json[\"title\"]}\", \"tool_arguments\": {schema_regex}}}'\n",
    "    elif callable(tool):\n",
    "        schema_json = get_schema_from_signature(tool)\n",
    "        schema_str = json.dumps(schema_json).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{tool.__name__}\", \"tool_arguments\": {schema_regex}}}'\n",
    "    elif isinstance(tool, str):\n",
    "        schema_str = re.sub(r'\\s+', ' ', tool).strip()\n",
    "        schema_regex = build_regex_from_schema(schema_str, whitespace_pattern)\n",
    "        regex_str = f'{{\"tool_name\": \"{json.loads(schema_str)[\"title\"]}\", \"tool_arguments\": {schema_regex}}}'\n",
    "\n",
    "    # if sometimes:\n",
    "    #     regex_str = sometime_guide(regex_str)\n",
    "    if not isinstance(tool, list):\n",
    "        # regex_str = f\"{tool_call_start}{regex_str}{tool_call_end}\"\n",
    "        regex_str = f\"{regex_str}{tool_call_end}\"\n",
    "\n",
    "    # if not isinstance(tool, list):\n",
    "    #     regex_str = repeat_regex_pattern(regex_str, n_tool_calls)\n",
    "\n",
    "    return regex_str, schema_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(\n",
    "    tool_schema,\n",
    "    tool_list_start=\"<tool>\",\n",
    "    tool_list_end=\"</tools>\",\n",
    "    tool_call_start=\"<tool_call>\",\n",
    "    tool_call_end=\"</tool_call>\",\n",
    "    tool_response_start=\"<tool_response>\",\n",
    "    tool_response_end=\"</tool_response>\"\n",
    "    ):\n",
    "\n",
    "    system_prompt = \"\"\"You are a function calling AI model. Your job is to answer the user's questions and you may call one or more functions to do this.\n",
    "\n",
    "\n",
    "    Please use your own judgment as to whether or not you should call a function. In particular, you must follow these guiding principles:\n",
    "    1. You may call one or more functions to assist with the user query. You should call multiple functions when the user asks you to.\n",
    "    2. You do not need to call a function. If none of the functions can be used to answer the user's question, please do not make the function call.\n",
    "    3. Don't make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters.\n",
    "    4. You may assume the user has implemented the function themselves.\n",
    "    5. You may assume the user will call the function on their own. You should NOT ask the user to call the function and let you know the result; they will do this on their own.\n",
    "\n",
    "\n",
    "    You can only call functions according the following formatting rules:\n",
    "    Rule 1: All the functions you have access to are contained within {tool_list_start}{tool_list_end} XML tags. You cannot use any functions that are not listed between these tags.\n",
    "\n",
    "    Rule 2: For each function call return a json object (using quotes) with function name and arguments within {tool_call_start}\\n{{ }}\\n{tool_call_end} XML tags as follows:\n",
    "    * With arguments:\n",
    "    {tool_call_start}\\n{{\"tool_name\": \"function_name\", \"tool_arguments\": {{\"argument_1_name\": \"value\", \"argument_2_name\": \"value\"}} }}\\n{tool_call_end}\n",
    "    * Without arguments:\n",
    "    {tool_call_start}\\n{{ \"tool_name\": \"function_name\", \"tool_arguments\": {{}} }}\\n{tool_call_end}\n",
    "    In between {tool_call_start} and{tool_call_end} tags, you MUST respond in a valid JSON schema.\n",
    "    In between the {tool_call_start} and {tool_call_end} tags you MUST only write in json; no other text is allowed.\n",
    "\n",
    "    Rule 3: If user decides to run the function, they will output the result of the function call between the {tool_response_start} and {tool_response_start} tags. If it answers the user's question, you should incorporate the output of the function in your answer.\n",
    "\n",
    "\n",
    "    Here are the tools available to you:\n",
    "    {tool_list_start}\\n{tool_schema}\\n{tool_list_end}\n",
    "\n",
    "    Remember, don't make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters. Do not be afraid to ask.\n",
    "    \"\"\"\n",
    "\n",
    "    return system_prompt.format(\n",
    "        tool_list_start=tool_list_start,\n",
    "        tool_list_end=tool_list_end,\n",
    "        tool_call_start=tool_call_start,\n",
    "        tool_call_end=tool_call_end,\n",
    "        tool_response_start=tool_response_start,\n",
    "        tool_response_end=tool_response_end,\n",
    "        tool_schema=tool_schema,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tool(text):\n",
    "    return \"<tool_call>\" in text and \"</tool_call>\" in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tools(text):\n",
    "    \"\"\"Return a list of all tools that match the tool_regex and is independent of `tool_call_start` and `tool_call_end`. This works for multiple functions.\n",
    "    This works \"\"\"\n",
    "\n",
    "    tool_regex = r'\\{\"tool_name\": \"([^\"]+)\", \"tool_arguments\": (\\{[^{}]*\\})\\}'\n",
    "    matches = re.findall(tool_regex, text)\n",
    "    tool_calls = []\n",
    "    for match in matches:\n",
    "        tool_name = match[0]\n",
    "        tool_arguments = json.loads(match[1])\n",
    "        tool_calls.append({'tool_name': tool_name, 'tool_arguments': tool_arguments})\n",
    "    return tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfcl_format(tool_calls):\n",
    "    tool_strs = []\n",
    "    for tool_call in tool_calls:\n",
    "        args, name = tool_call[\"tool_arguments\"], tool_call[\"tool_name\"]\n",
    "        args_string = ', '.join([f\"{key}='{value}'\" if isinstance(value, str) else f\"{key}={value}\" for key, value in args.items()])\n",
    "        tool_str = f'{name}({args_string})'\n",
    "        tool_strs.append(tool_str)\n",
    "    result = '[' + ', '.join(tool_strs) + ']'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate  Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_text(messages, regex_str=None, stop_token=None, max_tokens=4096):\n",
    "\n",
    "#     extra_body = {}\n",
    "#     if regex_str:\n",
    "#         extra_body = dict(guided_regex=regex_str, guided_decoding_backend=\"outlines\")\n",
    "\n",
    "#     completion = client.chat.completions.create(\n",
    "#         model=\"databricks/dbrx-instruct\",\n",
    "#         max_tokens=max_tokens,\n",
    "#         messages=messages,\n",
    "#         stop=stop_token,\n",
    "#         extra_body=extra_body,\n",
    "#         )\n",
    "\n",
    "#     raw_text = completion.choices[0].message.content\n",
    "#     finish_reason = completion.choices[0].stop_reason\n",
    "#     return raw_text, finish_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_structured(messages, regex_str, stop_token=None, max_tokens=4096):\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"databricks/dbrx-instruct\",\n",
    "      max_tokens=max_tokens,\n",
    "      messages=messages,\n",
    "      stop=stop_token,\n",
    "      extra_body=dict(guided_regex=regex_str, guided_decoding_backend=\"outlines\"),\n",
    "      )\n",
    "    raw_text = completion.choices[0].message.content\n",
    "    finish_reason = completion.choices[0].stop_reason\n",
    "    return raw_text, finish_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unstructured(messages, stop_token=None, max_tokens=4096):\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"databricks/dbrx-instruct\",\n",
    "      max_tokens=max_tokens,\n",
    "      messages=messages,\n",
    "      stop=stop_token,\n",
    "      extra_body={},\n",
    "      )\n",
    "    raw_text = completion.choices[0].message.content\n",
    "    finish_reason = completion.choices[0].stop_reason\n",
    "    return raw_text, finish_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_text(mode, messages, regex_str, structured=True, max_tokens=500, verbose=0):\n",
    "\n",
    "#   if mode == \"vllm-endpoint\":\n",
    "\n",
    "#     extra_body = {}\n",
    "#     if structured:\n",
    "#       extra_body=dict(guided_regex=regex_str, guided_decoding_backend=\"outlines\")\n",
    "\n",
    "#     completion = client.chat.completions.create(\n",
    "#       model=\"databricks/dbrx-instruct\",\n",
    "#       max_tokens=max_tokens,\n",
    "#       messages=messages,\n",
    "#       extra_body=extra_body,\n",
    "#       )\n",
    "#     raw_text = completion.choices[0].message.content\n",
    "#   elif mode == \"transformers\":\n",
    "\n",
    "#     if verbose >= 1:\n",
    "#       print(\"Creating Generator...\", end=\"\\t\")\n",
    "\n",
    "#     generator = generate.text(model)\n",
    "#     if structured:\n",
    "#       generator = generate.regex(model, regex_str)\n",
    "#       generator.format_sequence = lambda x: x #json.loads(x)\n",
    "\n",
    "\n",
    "#     if verbose >= 1:\n",
    "#       print(\"Done\\nGenerating Text...\", end=\"\\t\")\n",
    "\n",
    "#     rng_seed = 420\n",
    "#     rng = torch.Generator(device=\"cuda\")\n",
    "#     rng.manual_seed(rng_seed)\n",
    "#     prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "#     raw_text = generator(prompt, rng=rng, max_tokens=max_tokens)\n",
    "\n",
    "#     if verbose >= 1:\n",
    "#       print(\"Done\")\n",
    "\n",
    "#   return raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(sender: str, recipient: str, message: str):\n",
    "    return \"Hi\"\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "\n",
    "schema = \"\"\"\n",
    "{\n",
    "  \"title\": \"User\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"name\": {\"type\": \"string\"},\n",
    "    \"last_name\": {\"type\": \"string\"},\n",
    "    \"id\": {\"type\": \"integer\"}\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "tools = [send_email, User, schema]\n",
    "\n",
    "user_query = \"\"\"\n",
    "Can you send an email from Alice (alice@gmail.com) to Bob (bob@databricks.com) saying 'We cracked the code!'?\n",
    "And can you also make two user profiles, one for Alice and one for Bob?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query:\t What is the Electric field at 3m from a point charge with a value of 4C? Also, calculate the magnetic field for an electric current of 0.5A flowing through a solenoid having 25 turns per meter and a length of 2m.\n",
      "Tools:\t\n",
      "\t {'name': 'physics.magnetic_field', 'description': 'Calculate magnetic field for given current flowing through solenoid.', 'parameters': {'type': 'dict', 'properties': {'current': {'type': 'float', 'description': 'Electric current in Amperes.'}, 'turnsPerMeter': {'type': 'float', 'description': 'Number of turns of solenoid per meter.'}, 'length': {'type': 'float', 'description': 'Length of the solenoid in meters.'}}, 'required': ['current', 'turnsPerMeter', 'length']}}\n",
      "\t {'name': 'physics.electric_field', 'description': 'Calculate electric field for a given point charge and distance.', 'parameters': {'type': 'dict', 'properties': {'charge': {'type': 'float', 'description': 'Value of point charge in Coulombs.'}, 'distance': {'type': 'float', 'description': 'Distance from the point charge in meters.'}}, 'required': ['charge', 'distance']}}\n",
      "Solution:\t\n",
      "\t ('physics.electric_field', {'charge': [4.0], 'distance': [3.0]})\n",
      "\t ('physics.magnetic_field', {'current': [0.5], 'turnsPerMeter': [25.0], 'length': [2.0]})\n"
     ]
    }
   ],
   "source": [
    "questions_path = \"../berkeley-function-call-leaderboard/data/gorilla_openfunctions_v1_test_parallel_multiple_function.json\"\n",
    "solutions_path = \"../berkeley-function-call-leaderboard/data/possible_answer/gorilla_openfunctions_v1_test_parallel_multiple_function.json\"\n",
    "\n",
    "questions = []\n",
    "with open(questions_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(json.loads(line))\n",
    "\n",
    "solutions = []\n",
    "with open(solutions_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        solutions.append(json.loads(line))\n",
    "\n",
    "idx = 11\n",
    "\n",
    "question = questions[idx]\n",
    "user_query = question[\"question\"]\n",
    "tools = question[\"function\"]\n",
    "if not isinstance(tools, list):\n",
    "    tools = [tools]\n",
    "\n",
    "solution = solutions[idx]\n",
    "n_tools_used = len(solution)\n",
    "\n",
    "print(\"User Query:\\t\", user_query)\n",
    "print(\"Tools:\\t\")\n",
    "for tool in tools:\n",
    "    print(\"\\t\", tool)\n",
    "print(\"Solution:\\t\")\n",
    "for tool in solution.items():\n",
    "    print(\"\\t\", tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex:\n",
      "(?:{\"tool_name\": \"physics.magnetic_field\", \"tool_arguments\": \\{[\\n ]*\"current\"[\\n ]*:[\\n ]*(-)?((0|[1-9][0-9]*))(\\.[0-9]+)?([eE][+-][0-9]+)?[\\n ]*,[\\n ]*\"turnsPerMeter\"[\\n ]*:[\\n ]*(-)?((0|[1-9][0-9]*))(\\.[0-9]+)?([eE][+-][0-9]+)?[\\n ]*,[\\n ]*\"length\"[\\n ]*:[\\n ]*(-)?((0|[1-9][0-9]*))(\\.[0-9]+)?([eE][+-][0-9]+)?[\\n ]*\\}}</tool_call>|{\"tool_name\": \"physics.electric_field\", \"tool_arguments\": \\{[\\n ]*\"charge\"[\\n ]*:[\\n ]*(-)?((0|[1-9][0-9]*))(\\.[0-9]+)?([eE][+-][0-9]+)?[\\n ]*,[\\n ]*\"distance\"[\\n ]*:[\\n ]*(-)?((0|[1-9][0-9]*))(\\.[0-9]+)?([eE][+-][0-9]+)?[\\n ]*\\}}</tool_call>)\n",
      "\n",
      "Schemas:\n",
      "{\"title\": \"physics.magnetic_field\", \"type\": \"object\", \"description\": \"Calculate magnetic field for given current flowing through solenoid.\", \"properties\": {\"current\": {\"type\": \"number\", \"description\": \"Electric current in Amperes. This is a float type value.\", \"format\": \"float\"}, \"turnsPerMeter\": {\"type\": \"number\", \"description\": \"Number of turns of solenoid per meter. This is a float type value.\", \"format\": \"float\"}, \"length\": {\"type\": \"number\", \"description\": \"Length of the solenoid in meters. This is a float type value.\", \"format\": \"float\"}}, \"required\": [\"current\", \"turnsPerMeter\", \"length\"]}\n",
      "{\"title\": \"physics.electric_field\", \"type\": \"object\", \"description\": \"Calculate electric field for a given point charge and distance.\", \"properties\": {\"charge\": {\"type\": \"number\", \"description\": \"Value of point charge in Coulombs. This is a float type value.\", \"format\": \"float\"}, \"distance\": {\"type\": \"number\", \"description\": \"Distance from the point charge in meters. This is a float type value.\", \"format\": \"float\"}}, \"required\": [\"charge\", \"distance\"]}\n"
     ]
    }
   ],
   "source": [
    "regex_str, tool_schema = tool_to_regex(tools, n_tool_calls=1)\n",
    "\n",
    "print(f\"Regex:\\n{regex_str}\\n\")\n",
    "print(f\"Schemas:\\n{tool_schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a function calling AI model. Your job is to answer the user\\'s questions and you may call one or more functions to do this.\\n\\n\\n    Please use your own judgment as to whether or not you should call a function. In particular, you must follow these guiding principles:\\n    1. You may call one or more functions to assist with the user query. You should call multiple functions when the user asks you to.\\n    2. You do not need to call a function. If none of the functions can be used to answer the user\\'s question, please do not make the function call.\\n    3. Don\\'t make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters.\\n    4. You may assume the user has implemented the function themselves.\\n    5. You may assume the user will call the function on their own. You should NOT ask the user to call the function and let you know the result; they will do this on their own.\\n\\n\\n    You can only call functions according the following formatting rules:\\n    Rule 1: All the functions you have access to are contained within <tool></tools> XML tags. You cannot use any functions that are not listed between these tags.\\n\\n    Rule 2: For each function call return a json object (using quotes) with function name and arguments within <tool_call>\\n{ }\\n</tool_call> XML tags as follows:\\n    * With arguments:\\n    <tool_call>\\n{\"tool_name\": \"function_name\", \"tool_arguments\": {\"argument_1_name\": \"value\", \"argument_2_name\": \"value\"} }\\n</tool_call>\\n    * Without arguments:\\n    <tool_call>\\n{ \"tool_name\": \"function_name\", \"tool_arguments\": {} }\\n</tool_call>\\n    In between <tool_call> and</tool_call> tags, you MUST respond in a valid JSON schema.\\n    In between the <tool_call> and </tool_call> tags you MUST only write in json; no other text is allowed.\\n\\n    Rule 3: If user decides to run the function, they will output the result of the function call between the <tool_response> and <tool_response> tags. If it answers the user\\'s question, you should incorporate the output of the function in your answer.\\n\\n\\n    Here are the tools available to you:\\n    <tool>\\n{\"title\": \"physics.magnetic_field\", \"type\": \"object\", \"description\": \"Calculate magnetic field for given current flowing through solenoid.\", \"properties\": {\"current\": {\"type\": \"number\", \"description\": \"Electric current in Amperes. This is a float type value.\", \"format\": \"float\"}, \"turnsPerMeter\": {\"type\": \"number\", \"description\": \"Number of turns of solenoid per meter. This is a float type value.\", \"format\": \"float\"}, \"length\": {\"type\": \"number\", \"description\": \"Length of the solenoid in meters. This is a float type value.\", \"format\": \"float\"}}, \"required\": [\"current\", \"turnsPerMeter\", \"length\"]}\\n{\"title\": \"physics.electric_field\", \"type\": \"object\", \"description\": \"Calculate electric field for a given point charge and distance.\", \"properties\": {\"charge\": {\"type\": \"number\", \"description\": \"Value of point charge in Coulombs. This is a float type value.\", \"format\": \"float\"}, \"distance\": {\"type\": \"number\", \"description\": \"Distance from the point charge in meters. This is a float type value.\", \"format\": \"float\"}}, \"required\": [\"charge\", \"distance\"]}\\n</tools>\\n\\n    Remember, don\\'t make assumptions about what values to plug into functions. If you are missing the parameters to make a function call, please ask the user for the parameters. Do not be afraid to ask.\\n    '}\n",
      "{'role': 'user', 'content': 'What is the Electric field at 3m from a point charge with a value of 4C? Also, calculate the magnetic field for an electric current of 0.5A flowing through a solenoid having 25 turns per meter and a length of 2m.'}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = get_system_prompt(tool_schema)\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_query}\n",
    "  ]\n",
    "\n",
    "for message in messages:\n",
    "  print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tools(messages, tool_call_start=\"<tool_call>\", tool_call_end=\"</tool_call>\", max_tool_calls=5, verbose=0):\n",
    "\n",
    "    n_tool_calls = 0\n",
    "    tool_calls = []\n",
    "\n",
    "    text, finish_reason = generate_unstructured(messages, stop_token=tool_call_start)\n",
    "    text += tool_call_start\n",
    "    messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "    if verbose: print(\"-\"*70, \"\\n\", \"(Finish:\", finish_reason, \")\\n\", text)\n",
    "\n",
    "    while n_tool_calls < max_tool_calls and finish_reason == tool_call_start:\n",
    "\n",
    "        text, finish_reason = generate_structured(messages, stop_token=tool_call_end, regex_str=regex_str)\n",
    "        tool_calls.append(json.loads(text))\n",
    "        text += tool_call_end\n",
    "        messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "        if verbose: print(\"-\"*70, \"\\n\", \"(Finish:\", finish_reason, \")\\n\", text)\n",
    "\n",
    "        n_tool_calls += 1\n",
    "\n",
    "        text, finish_reason = generate_unstructured(messages, stop_token=tool_call_start)\n",
    "        text += tool_call_start\n",
    "        messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "        if verbose: print(\"-\"*70, \"\\n\", \"(Finish:\", finish_reason, \")\\n\", text)\n",
    "\n",
    "    return messages, tool_calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      " (Finish: <tool_call> )\n",
      " To answer your first question, I can use the \"physics.electric_field\" function. I will need the \"charge\" and \"distance\" values to make the function call. You have provided the \"charge\" value as 4C and the \"distance\" value as 3m. Here is the function call:\n",
      "\n",
      "<tool_call>\n",
      "---------------------------------------------------------------------- \n",
      " (Finish: </tool_call> )\n",
      " {\"tool_name\": \"physics.electric_field\", \"tool_arguments\": {\"charge\": 4, \"distance\": 3}}</tool_call>\n",
      "---------------------------------------------------------------------- \n",
      " (Finish: <tool_call> )\n",
      " To answer your second question, I can use the \"physics.magnetic_field\" function. I will need the \"current\", \"turnsPerMeter\", and \"length\" values to make the function call. You have provided the \"current\" value as 0.5A, the \"turnsPerMeter\" value as 25, and the \"length\" value as 2m. Here is the function call:\n",
      "\n",
      "<tool_call>\n",
      "---------------------------------------------------------------------- \n",
      " (Finish: </tool_call> )\n",
      " {\"tool_name\": \"physics.magnetic_field\", \"tool_arguments\": {\"current\": 0.5, \"turnsPerMeter\": 25, \"length\": 2}}</tool_call>\n",
      "---------------------------------------------------------------------- \n",
      " (Finish: 100279 )\n",
      " Now, I will wait for the function call results to be provided between the <tool_response> and </tool_response> tags. Once I have the results, I will incorporate them into my answer.\n",
      "\n",
      "<tool_response>\n",
      "</tool_response>\n",
      "\n",
      "Based on the provided function call results, the electric field at 3m from a point charge with a value of 4C is <tool_response_value_1>, and the magnetic field for an electric current of 0.5A flowing through a solenoid having 25 turns per meter and a length of 2m is <tool_response_value_2>.<tool_call>\n",
      "[{'tool_name': 'physics.electric_field', 'tool_arguments': {'charge': 4, 'distance': 3}}, {'tool_name': 'physics.magnetic_field', 'tool_arguments': {'current': 0.5, 'turnsPerMeter': 25, 'length': 2}}]\n"
     ]
    }
   ],
   "source": [
    "messages, tools = call_tools(messages, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[physics.electric_field(charge=4, distance=3), physics.magnetic_field(current=0.5, turnsPerMeter=25, length=2)]'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfcl_format(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gorilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
